<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners -->
  <meta name="description" content="Follow the Flow: Improving T2I Generation by Cleaning Token Representations and Mitigating Semantic Leakage through Detokenization.">
  <meta property="og:title" content="Follow the Flow: On Information Flow Across Textual Tokens in Text-to-Image Models"/>
  <meta property="og:description" content="Discover how a deep analysis of token representations in text-to-image models leads to a 21% reduction in errors and an 85% mitigation of semantic leakage using simple, training-free interventions.">
  <meta property="og:url" content="https://yourdomain.com/follow-the-flow"/>
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>

  <meta name="twitter:title" content="Follow the Flow: On Information Flow Across Textual Tokens in Text-to-Image Models">
  <meta name="twitter:description" content="Explore our project demonstrating improved image generation through refined token analysis and detokenization techniques that enhance both accuracy and alignment.">
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="keywords" content="text-to-image, detokenization, semantic leakage, token representation, diffusion models">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Follow the Flow: On Information Flow Across Textual Tokens in Text-to-Image Models</title>
  <link rel="icon" type="image/x-icon" href="static/images/wave.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Follow the Flow: On Information Flow Across Textual Tokens in Text-to-Image Models</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://yourinstitution.edu/~guykaplan" target="_blank">Guy Kaplan</a><sup>*</sup>,</span>
              <span class="author-block">
                <a href="https://yourinstitution.edu/~mtoker" target="_blank">Michael Toker</a><sup>*</sup>,</span>
              <span class="author-block">
                <a href="https://yourinstitution.edu/~yuvalreif" target="_blank">Yuval Reif</a>,</span>
              <span class="author-block">
                <a href="https://yourinstitution.edu/~yonatan" target="_blank">Yonatan Belinkov</a>,</span>
              <span class="author-block">
                <a href="https://yourinstitution.edu/~royschwartz" target="_blank">Roy Schwartz</a>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">Hebrew University of Jerusalem &amp; Technion – Israel Institute of Technology<br>Preprint</span>
              <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
            </div>

            <div class="publication-links">
              <!-- Paper PDF link -->
              <span class="link-block">
                <a href="static/pdfs/follow_the_flow.pdf" target="_blank" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>

              <!-- Github link -->
              <span class="link-block">
                <a href="https://github.com/tokeron/lens" target="_blank" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                </a>
              </span>

              <!-- ArXiv abstract link -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2504.01137" target="_blank" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Teaser video-->
  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <video poster="" id="tree" autoplay controls muted loop height="100%">
          <!-- Your video here -->
          <source src="static/videos/zebra.mp4" type="video/mp4">
        </video>
        <h2 class="subtitle has-text-centered">
          <strong>Eliminating Semantic Leakage with Uncontextualized Representations</strong><br>
          By selectively removing redundant tokens and patching leaked representations, our method corrects errors – for instance, turning a misinterpreted crosswalk into the intended zebra.
        </h2>
      </div>
    </div>
  </section>
  <!-- End teaser video -->

  <!-- Abstract Section -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Text-to-Image (T2I) models often suffer from issues such as semantic leakage, incorrect feature binding, and omissions of key concepts in the generated image. This work studies these phenomena by looking into the role of information flow between textual token representations. To this end, we generate images by applying the diffusion component on a subset of contextual token representations in a given prompt and observe several interesting phenomena. First, in many cases, a word or multiword expression is fully represented by one or two tokens, while other tokens are redundant. For example, in "San Francisco's Golden Gate Bridge", the token "gate" alone captures the full expression. 
We demonstrate the redundancy of these tokens by removing them after textual encoding and generating an image from the resulting representation. Surprisingly, we find that this process not only maintains image generation performance, but also reduces errors by 21\% compared to standard generation. We then show that information can also flow between <em>different expressions</em> in a sentence, which often leads to <em>semantic leakage</em>. Based on this observation, we propose a simple, training-free method to mitigate semantic leakage: replacing the leaked item's representation after the textual encoding with its uncontextualized representation. Remarkably, this simple approach reduces semantic leakage by 85\%. Overall, our work provides a comprehensive analysis of information flow across textual tokens in T2I models, offering both novel insights and practical benefits.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Key Findings Section for a Quick Overview -->
  <section class="section" id="key-findings">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Key Findings</h2>
      <div class="content">
        <ul>
          <li><strong>Concentrated Information:</strong> In most cases, a lexical item’s meaning is concentrated in just one or two tokens.</li>
          <li><strong>Redundancy Reduction:</strong> Removing redundant tokens improves image generation accuracy, lowering errors by 21%.</li>
          <li><strong>Semantic Leakage:</strong> In 11% of cases, tokens unintentionally leak information between unrelated items, potentially leading to misinterpretations.</li>
          <li><strong>Effective Patching:</strong> Replacing leaked token representations with their uncontextualized versions mitigates semantic leakage by 85%.</li>
          <li><strong>Efficient Token Identification:</strong> A simple k-NN classifier predicts redundant tokens with 92% precision, enabling practical improvements in T2I pipelines.</li>
          <li><strong>Catastrophic Negligence:</strong> In about 7% of cases, a lexical item is accurately encoded but fails to appear in the final image, highlighting a disconnect between the encoder and the decoder.</li>
        </ul>
      </div>
    </div>
  </section>

<!-- Motivation Section -->
<section class="motivation">
  <div class="container is-max-desktop">
    <div class="content">
      <h2>Motivation</h2>
      <p>
        Despite the impressive advances in text-to-image models, several key issues still persist:
      </p>
      <ul>
        <li>
          <strong>Missing Attribute Binding:</strong> In prompts such as “a pink colored giraffe,” the model may fail to accurately apply the pink attribute to the giraffe, generating a normal giraffe instead.
        </li>
        <li>
          <strong>Semantic Leakage:</strong> For example, a prompt like “a person wearing a cone hat is eating” can mistakenly merge the concept of the hat with the act of eating—generating an ice-cream cone hat.
        </li>
        <li>
          <strong>Catastrophic Neglect:</strong> Sometimes, as with “a tuba made of flower petals,” the primary object (the tuba) may be completely omitted, leaving only flower petals in the resulting image.
        </li>
      </ul>
      <p>
        Traditionally, most approaches have addressed these challenges from the diffusion model's perspective—by tweaking the cross-attention mechanism or optimizing image latents. While these methods can mitigate certain errors, they do not solve all cases.
      </p>
      <p>
        This observation raises a fundamental question: <em>Could these issues originate earlier in the pipeline, within the text encoder itself?</em>
      </p>
      <figure class="example-issues">
        <img src="static/images/generation_issues.png"
             alt="Examples illustrating semantic leakage, missing attribute binding, and catastrophic neglect.">
        <figcaption class="has-text-centered">
          Left: “a tuba made of flower petals” (the tuba is neglected).<br>
          Middle: “a pink colored giraffe” (attribute binding is missing).<br>
          Right: “a person wearing cone hat is eating” (semantic leakage from eating to the cone hat).
        </figcaption>
      </figure>
    </div>
  </div>
</section>
<!-- End Motivation Section -->

  <!-- In-Item Analysis Section -->
  <section class="in-item-analysis" style="margin-bottom: 2rem;">
    <div class="container is-max-desktop">
      <div class="content">
        <h2>Tracing Token Representations in the Text Encoder</h2>
        <p>
          We analyze how information is distributed within each lexical item by generating images from individual token representations. Our experiments show that for most words or expressions, only one or two tokens effectively carry the meaning, while the rest are largely redundant.
        </p>
        <p>
          By masking out these non-representative tokens before image generation, we not only maintain the intended visual output but often see improvements in accuracy—with a notable 21% error reduction. This confirms that a more focused token representation better aligns the generated image with the original prompt.
        </p>
        <figure>
          <img src="static/images/analysis_in_item.png" alt="Visualization of individual token representations within a lexical item.">
          <figcaption>
            Analysis of in-item information flow: Only select tokens capture the full semantic load of the lexical item.
          </figcaption>
        </figure>
        <figure>
          <img src="static/images/repreentative_tokens.jpeg" alt="Highlighted representative tokens among all token representations.">
          <figcaption>
            Typically, one or two tokens are representative while others are redundant.
          </figcaption>
        </figure>
              <p>
        To further validate this observation, we remove the unrepresentative (redundant) tokens and regenerate the image. The results confirm that omitting these tokens not only reproduces the original image but can also improve aspects like attribute binding.
      </p>
      <figure>
        <!-- Redundant token removal examples (converted to a regular image) -->
        <img src="static/images/redundant_removal.png" alt="Redundant removal qualitative results">
        <figcaption>
    Redundant token removal: The top row shows images generated solely from the representative ( <strong>bolded </strong>) tokens after masking out uninformative tokens, while the bottom row shows the original outputs. On the <em>left</em>, removal has little effect on the overall generation; on the <em>right</em>, it significantly improves the visual alignment with the prompt.
        </figcaption>
      </figure>
      </div>
    </div>
  </section>

  <!-- Inter-Item Analysis Section -->
  <section class="inter-item-analysis" style="margin-bottom: 2rem;">
    <div class="container is-max-desktop">
      <div class="content">
        <h2>Information Flow Between Lexical Items</h2>
        <p>
          Beyond individual tokens, our work examines how different lexical items interact during encoding. In 89% of cases, items remain independent; however, in the remaining 11%, uninteded interactions occurs—for example, the word “bats” may inadvertently adopt features of “baseball,” leading to a generate a baseball bat instead of the animals "bats".
        </p>
        <figure>
          <img src="static/images/items_flow.png" alt="Examples of information flow between items.">
        <figcaption>
          <strong> Examples of information flow between items. </strong>
          Top: Images generated from a 
          <span style="color: purple;">lexical item</span> 
          encoded alongside 
          <span style="color: blue;">another item</span> 
          that alters its representation. 
          Bottom: Images generated from the uncontextualized representation of the same lexical item. 
          The first three images (from the left) demonstrate correct information flow, while the last image (far right) demonstrates incorrect information flow.
        </figcaption>
        </figure>
        <p>
          We propose a simple yet effective method: by re-encoding the suspected leaked token in isolation and <em>patching</em> it into the prompt’s representation, we reduce semantic leakage errors by 85%. This approach demonstrates that addressing the issue at the token level—in the text encoder—can significantly improve overall generation quality.
        </p>
        <figure>
          <img src="static/images/cleaning_method.png" alt="Method for removing semantic leakage by replacing the leaked concept representation.">
        <figcaption>
          <strong> Removing semantic leakage by replacing the contextually leaked concept representation. </strong>
          (1) Regular generation produces an image showing a crosswalk to the right of a bus station. 
          (2) Generation from the prompt “standing zebra,” without any context, results in the correct interpretation of the zebra as an animal. 
          (3) Using the original prompt but substituting the leaked concept with its uncontextualized representation yields the desired image.
        </figcaption>
        </figure>
      <p>
        In practice, this patching step significantly reduces misinterpretations. By restoring each item’s “clean” encoding, we ensure that contextual cues do not unintentionally override the core meaning of an entity. 
      </p>
      </div>
    </div>
  </section>

  <!-- Catastrophic Negligence Section -->
  <section class="catastrophic-negligence" style="margin-bottom: 2rem;">
    <div class="container is-max-desktop">
      <div class="content">
        <h2>Catastrophic Negligence</h2>
        <p>
          In a small percentage of cases (around 7%), even though the text encoder captures the intended concept, the final image omits it completely—a phenomenon we term catastrophic negligence. Our analysis, supported by tools like Patchscopes, suggests that this may be due to insufficient training examples or difficulties in rendering certain entities. 
        </p>
        <figure>
          <img src="static/images/Catastrophic_negligence.png" alt="Examples of catastrophic negligence where key concepts are omitted.">
          <figcaption>
            Despite accurate encoding, some items are entirely missing from the generated image of the relevant tokens.
          </figcaption>
        </figure>
      </div>
    </div>
  </section>

  <!-- Supplementary: In-Item Token Distribution Section -->
  <section class="supplementary in-item-tokens" style="margin-bottom: 2rem;">
    <div class="container is-max-desktop">
      <div class="content">
        <h2>Supplementary: In-Item Token Distribution</h2>
        <p>
          Our supplementary analysis further illustrates how semantic weight is unevenly distributed among tokens. In many cases, a single or a couple of sub-tokens carry most of the meaning, while others contribute little. This insight opens up avenues for more efficient token-level interventions in T2I systems.
        </p>
        <figure>
          <img src="static/images/detokenization.gif" alt="Animated view of token-level concept representation.">
          <figcaption class="has-text-centered">
            An animated demonstration of how only a few tokens carry the primary semantic load.
          </figcaption>
        </figure>
      </div>
    </div>
  </section>

  <!-- BibTeX citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
@misc{kaplan2025followflowinformationflow,
      title={Follow the Flow: On Information Flow Across Textual Tokens in Text-to-Image Models}, 
      author={Guy Kaplan and Michael Toker and Yuval Reif and Yonatan Belinkov and Roy Schwartz},
      year={2025},
      eprint={2504.01137},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2504.01137}, 
}
      </code></pre>
    </div>
  </section>

  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
              You are free to borrow the source code of this website, we just ask that you link back to this page in the footer.<br>
              This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>
</html>
