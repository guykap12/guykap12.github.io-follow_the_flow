<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners -->
  <meta name="description" content="Follow the Flow: Improving T2I Generation by Cleaning Token Representations and Mitigating Semantic Leakage through Detokenization.">
  <meta property="og:title" content="Follow the Flow: On Information Flow Across Textual Tokens in Text-to-Image Models"/>
  <meta property="og:description" content="Discover how detokenization—focusing on the most representative tokens—can improve image generation, as illustrated by our zebra and pink giraffe examples.">
  <meta property="og:url" content="https://yourdomain.com/follow-the-flow"/>
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>

  <meta name="twitter:title" content="Follow the Flow: On Information Flow Across Textual Tokens in Text-to-Image Models">
  <meta name="twitter:description" content="Explore our project demonstrating improved image generation through token cleaning and detokenization techniques.">
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="keywords" content="text-to-image, detokenization, semantic leakage, token representation, diffusion models">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Follow the Flow: On Information Flow Across Textual Tokens in Text-to-Image Models</title>
  <link rel="icon" type="image/x-icon" href="static/images/wave.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Follow the Flow: On Information Flow Across Textual Tokens in Text-to-Image Models</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://yourinstitution.edu/~guykaplan" target="_blank">Guy Kaplan</a><sup>*</sup>,</span>
              <span class="author-block">
                <a href="https://yourinstitution.edu/~mtoker" target="_blank">Michael Toker</a><sup>*</sup>,</span>
              <span class="author-block">
                <a href="https://yourinstitution.edu/~yuvalreif" target="_blank">Yuval Reif</a>,</span>
              <span class="author-block">
                <a href="https://yourinstitution.edu/~yonatan" target="_blank">Yonatan Belinkov</a>,</span>
              <span class="author-block">
                <a href="https://yourinstitution.edu/~royschwartz" target="_blank">Roy Schwartz</a>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">Hebrew University of Jerusalem &amp; Technion – Israel Institute of Technology<br>Preprint</span>
              <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
            </div>

            <div class="publication-links">
              <!-- Paper PDF link -->
              <span class="link-block">
                <a href="static/pdfs/follow_the_flow.pdf" target="_blank" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>

              <!-- Github link -->
              <span class="link-block">
                <a href="https://github.com/tokeron/lens" target="_blank" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                </a>
              </span>

              <!-- ArXiv abstract link -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2504.01137" target="_blank" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <!-- Your video here -->
        <source src="static/videos/zebra.mp4" type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <strong>Eliminating Semantic Leakage with Uncontextualized Representations</strong><br>
        When generating an image from the full prompt “a standing zebra to the right of a bus station”, the model mistakenly renders a <span style="color: red;">crosswalk</span> instead of a zebra. 
        However, using the concise prompt <span style="color: green;">“standing zebra”</span> correctly captures the animal. 
        Replacing the leaked concept with its uncontextualized representation then yields the desired image.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

  <!-- Paper abstract -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Text-to-image (T2I) models often suffer from semantic leakage and redundant token representations. Our work investigates the flow of information across textual tokens and demonstrates that focusing on the most representative tokens can improve image generation. By removing non-representative tokens, we achieve a 21% reduction in errors, and by patching leaked representations with uncontextualized tokens, we mitigate semantic leakage by 85%. This project illustrates these techniques through in-depth analysis and visual demonstrations.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

<!-- Motivation Section -->
<section class="motivation">
  <div class="container is-max-desktop">
    <div class="content">
      <h2>Motivation</h2>
      <p>
        Despite the impressive advances in text-to-image models, several key issues still persist:
      </p>
      <ul>
        <li>
          <strong>Semantic Leakage:</strong> For example, a prompt like “a person wearing a cone hat is eating” can mistakenly merge the concept of the hat with the act of eating—generating an ice-cream cone hat.
        </li>
        <li>
          <strong>Missing Attribute Binding:</strong> In prompts such as “a pink colored giraffe,” the model may fail to accurately apply the pink attribute to the giraffe, generating a normal giraffe instead.
        </li>
        <li>
          <strong>Catastrophic Neglect:</strong> Sometimes, as with “a tuba made of flower petals,” the primary object (the tuba) may be completely omitted, leaving only flower petals in the resulting image.
        </li>
      </ul>
      <p>
        Traditionally, most approaches have addressed these challenges from the diffusion model's perspective—by tweaking the cross-attention mechanism or optimizing image latents. While these methods can mitigate certain errors, they do not solve all cases.
      </p>
      <p>
        This observation raises a fundamental question: <em>Could these issues originate earlier in the pipeline, within the text encoder itself?</em>
      </p>
      <figure class="example-issues">
        <img src="static/images/generation_issues.png"
             alt="Examples illustrating semantic leakage, missing attribute binding, and catastrophic neglect.">
        <figcaption class="has-text-centered">
          Left: “a tuba made of flower petals” (the tuba is neglected).<br>
          Middle: “a pink colored giraffe” (attribute binding is missing).<br>
          Right: “a person wearing cone hat is eating” (semantic leakage from eating to the cone hat).
        </figcaption>
      </figure>
    </div>
  </div>
</section>
<!-- End Motivation Section -->

<!-- In-Item Analysis Section -->
<section class="in-item-analysis" style="margin-bottom: 2rem;">
  <div class="container is-max-desktop">
    <div class="content">
      <h2>Tracing Token Representations in the Text Encoder</h2>
      <p>
        Building on our motivation, we investigate whether the issues in image generation originate from the text encoder. To do so, we generate images for each token’s contextualized representation, allowing us to trace what each token contributes.
      </p>
      <p>
        As shown in the analysis below, we isolate each token from a lexical item and generate its corresponding image. This process reveals that only a subset of tokens effectively represents the intended concept.
      </p>
      <figure>
        <!-- Analysis of in-item token representations -->
        <img src="static/images/analysis_in_item.png" alt="Visualization of individual token representations within a lexical item.">
        <figcaption>
          Analysis of in-item information flow: Each token’s contextual representation is visualized to determine its contribution.
        </figcaption>
      </figure>
      <p>
        In our findings, only the representative tokens—those that capture the core meaning—contribute to generating the intended image. The remaining tokens, as highlighted in the view below, appear redundant.
      </p>
      <figure>
        <!-- Representative tokens highlighted -->
        <img src="static/images/repreentative_tokens.jpeg" alt="Highlighted representative tokens among all token representations.">
        <figcaption>
          Only a subset of tokens are representative of the lexical item’s concept.
        </figcaption>
      </figure>
      <p>
        To further validate this observation, we remove the unrepresentative (redundant) tokens and regenerate the image. The results confirm that omitting these tokens not only reproduces the original image but can also improve aspects like attribute binding.
      </p>
      <figure>
        <!-- Redundant token removal examples (converted to a regular image) -->
        <img src="static/images/redundant_removal.png" alt="Redundant removal qualitative results">
        <figcaption>
          Redundant token removal: Masking out unrepresentative tokens produces images that maintain or even enhance the original output.
        </figcaption>
      </figure>
    </div>
  </div>
</section>
<!-- End In-Item Analysis Section -->


<!-- Inter-Item Analysis Section -->
<section class="inter-item-analysis" style="margin-bottom: 2rem;">
  <div class="container is-max-desktop">
    <div class="content">
      <h2>Information Flow Between Lexical Items</h2>
      <p>
        Thus far, we have focused on how each token represents its own lexical item. Next, we examine whether information can flow <em>across</em> different items in the same prompt. Surprisingly, our analysis shows that in <strong>89%</strong> of cases, tokens only represent the concept they are part of. In other words, most lexical items remain unaffected by other items in the prompt.
      </p>
      <p>
        However, in the remaining <strong>11%</strong> of cases, a lexical item’s representation <em>is</em> influenced by another item. Sometimes this reflects the intended meaning of the prompt (e.g., combining attributes), but in other instances, it can cause undesired semantic leakage. The figure below illustrates both scenarios:
      </p>
      <figure>
        <img src="static/images/items_flow.png" alt="Examples of information flow between items.">
        <figcaption>
          <strong> Examples of information flow between items. </strong>
          Top: Images generated from a 
          <span style="color: purple;">lexical item</span> 
          encoded alongside 
          <span style="color: blue;">another item</span> 
          that alters its representation. 
          Bottom: Images generated from the uncontextualized representation of the same lexical item. 
          The first three images (from the left) demonstrate correct information flow, while the last image (far right) demonstrates incorrect information flow.
        </figcaption>
      </figure>
      <p>
        When unintended leakage occurs, we propose a simple solution: <em>patching</em> the leaked item’s representation with its “clean,” uncontextualized form. This process involves encoding the item separately, then replacing its potentially corrupted representation in the original prompt encoding. 
      </p>
      <figure>
        <img src="static/images/cleaning_method.png" alt="Method for removing semantic leakage by replacing the leaked concept representation.">
        <figcaption>
          <strong> Removing semantic leakage by replacing the contextually leaked concept representation. </strong>
          (1) Regular generation produces an image showing a crosswalk to the right of a bus station. 
          (2) Generation from the prompt “standing zebra,” without any context, results in the correct interpretation of the zebra as an animal. 
          (3) Using the original prompt but substituting the leaked concept with its uncontextualized representation yields the desired image.
        </figcaption>
      </figure>
      <p>
        In practice, this patching step significantly reduces misinterpretations. By restoring each item’s “clean” encoding, we ensure that contextual cues do not unintentionally override the core meaning of an entity. 
      </p>
    </div>
  </div>
</section>
<!-- End Inter-Item Analysis Section -->

  


  <!-- Additional Image Carousel (optional) -->
  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item">
            <img src="static/images/carousel1.jpg" alt="Additional image 1">
            <h2 class="subtitle has-text-centered">Image 1 Description</h2>
          </div>
          <div class="item">
            <img src="static/images/carousel2.jpg" alt="Additional image 2">
            <h2 class="subtitle has-text-centered">Image 2 Description</h2>
          </div>
          <div class="item">
            <img src="static/images/carousel3.jpg" alt="Additional image 3">
            <h2 class="subtitle has-text-centered">Image 3 Description</h2>
          </div>
          <div class="item">
            <img src="static/images/carousel4.jpg" alt="Additional image 4">
            <h2 class="subtitle has-text-centered">Image 4 Description</h2>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Youtube video presentation -->
  <section class="hero is-small is-light">
    <div class="hero-body">
      <div class="container">
        <h2 class="title is-3">Video Presentation</h2>
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <div class="publication-video">
              <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Paper poster -->
  <section class="hero is-small is-light">
    <div class="hero-body">
      <div class="container">
        <h2 class="title">Poster</h2>
        <iframe src="static/pdfs/sample.pdf" width="100%" height="550"></iframe>
      </div>
    </div>
  </section>

  <!-- BibTeX citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
@misc{kaplan2024follow,
  title={Follow the Flow: On Information Flow Across Textual Tokens in Text-to-Image Models},
  author={Kaplan, Guy and Toker, Michael and Reif, Yuval and Belinkov, Yonatan and Schwartz, Roy},
  year={2024},
  publisher={Preprint},
  url={https://yourdomain.com/follow-the-flow}
}
      </code></pre>
    </div>
  </section>

  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
              You are free to borrow the source code of this website, we just ask that you link back to this page in the footer.<br>
              This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>
</html>
