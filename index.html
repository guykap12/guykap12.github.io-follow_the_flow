<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners -->
  <meta name="description" content="Follow the Flow: Improving T2I Generation by Cleaning Token Representations and Mitigating Semantic Leakage through Detokenization.">
  <meta property="og:title" content="Follow the Flow: On Information Flow Across Textual Tokens in Text-to-Image Models"/>
  <meta property="og:description" content="Discover how a deep analysis of token representations in text-to-image models leads to a 21% reduction in errors and an 85% mitigation of semantic leakage using simple, training-free interventions.">
  <meta property="og:url" content="https://yourdomain.com/follow-the-flow"/>
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>

  <meta name="twitter:title" content="Follow the Flow: On Information Flow Across Textual Tokens in Text-to-Image Models">
  <meta name="twitter:description" content="Explore our project demonstrating improved image generation through refined token analysis and detokenization techniques that enhance both accuracy and alignment.">
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="keywords" content="text-to-image, detokenization, semantic leakage, token representation, diffusion models">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Follow the Flow: On Information Flow Across Textual Tokens in Text-to-Image Models</title>
  <link rel="icon" type="image/x-icon" href="static/images/wave.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Follow the Flow: On Information Flow Across Textual Tokens in Text-to-Image Models</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://yourinstitution.edu/~guykaplan" target="_blank">Guy Kaplan</a><sup>*</sup>,</span>
              <span class="author-block">
                <a href="https://yourinstitution.edu/~mtoker" target="_blank">Michael Toker</a><sup>*</sup>,</span>
              <span class="author-block">
                <a href="https://yourinstitution.edu/~yuvalreif" target="_blank">Yuval Reif</a>,</span>
              <span class="author-block">
                <a href="https://yourinstitution.edu/~yonatan" target="_blank">Yonatan Belinkov</a>,</span>
              <span class="author-block">
                <a href="https://yourinstitution.edu/~royschwartz" target="_blank">Roy Schwartz</a>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">Hebrew University of Jerusalem &amp; Technion – Israel Institute of Technology<br>Preprint</span>
              <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
            </div>

            <div class="publication-links">
              <!-- Paper PDF link -->
              <span class="link-block">
                <a href="static/pdfs/follow_the_flow.pdf" target="_blank" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>

              <!-- Github link -->
              <span class="link-block">
                <a href="https://github.com/tokeron/lens" target="_blank" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                </a>
              </span>

              <!-- ArXiv abstract link -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2504.01137" target="_blank" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Teaser video-->
  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <video poster="" id="tree" autoplay controls muted loop height="100%">
          <!-- Your video here -->
          <source src="static/videos/zebra.mp4" type="video/mp4">
        </video>
        <h2 class="subtitle has-text-centered">
          <strong>Eliminating Semantic Leakage with Uncontextualized Representations</strong><br>
          By selectively removing redundant tokens and patching leaked representations, our method corrects errors – for instance, turning a misinterpreted crosswalk into the intended zebra.
        </h2>
      </div>
    </div>
  </section>
  <!-- End teaser video -->

  <!-- Abstract Section -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Text-to-image models can suffer from semantic leakage, misbinding of attributes, and omissions of key concepts. In our work, we study how information flows across textual tokens during encoding. Our findings reveal that most lexical items are effectively represented by only one or two tokens, with the remaining tokens often redundant. By removing these non-representative tokens, we achieve a 21% reduction in generation errors. Furthermore, when contextual interference causes semantic leakage between unrelated items, we propose a training-free intervention—patching the leaked representation with its uncontextualized form—which reduces leakage by 85%. This dual approach not only clarifies the internal workings of T2I models but also offers practical methods to enhance image–text alignment.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Key Findings Section for a Quick Overview -->
  <section class="section" id="key-findings">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Key Findings</h2>
      <div class="content">
        <ul>
          <li><strong>Concentrated Information:</strong> In 89% of cases, a lexical item’s meaning is concentrated in just one or two tokens.</li>
          <li><strong>Redundancy Reduction:</strong> Removing redundant tokens improves image generation accuracy, lowering errors by 21%.</li>
          <li><strong>Semantic Leakage:</strong> In 11% of cases, tokens unintentionally leak information between unrelated items, leading to misinterpretations.</li>
          <li><strong>Effective Patching:</strong> Replacing leaked token representations with their uncontextualized versions mitigates semantic leakage by 85%.</li>
          <li><strong>Efficient Token Identification:</strong> A simple k-NN classifier predicts redundant tokens with 92% precision, enabling practical improvements in T2I pipelines.</li>
        </ul>
        <p>
          Whether you’re a technical reader or simply curious about how images are generated from text, these insights offer both a deep dive into model internals and actionable strategies to improve visual outputs.
        </p>
      </div>
    </div>
  </section>

  <!-- Motivation Section -->
  <section class="motivation">
    <div class="container is-max-desktop">
      <div class="content">
        <h2>Motivation</h2>
        <p>
          Despite impressive advances, text-to-image models still encounter challenges such as missing attribute binding, semantic leakage, and catastrophic neglect. Traditional methods often focus solely on tweaking the diffusion or attention mechanisms. Our work, however, examines the text encoder—the very first step—revealing that many errors originate from redundant or misaligned token representations. Understanding and intervening at this stage can dramatically improve the generated image quality.
        </p>
        <ul>
          <li>
            <strong>Missing Attribute Binding:</strong> For instance, a “pink colored giraffe” might produce a standard giraffe if the attribute isn’t correctly bound.
          </li>
          <li>
            <strong>Semantic Leakage:</strong> A prompt such as “a person wearing a cone hat is eating” may merge unrelated concepts, causing visual misinterpretation.
          </li>
          <li>
            <strong>Catastrophic Negligence:</strong> Some key concepts might be entirely omitted despite being well-represented in the text.
          </li>
        </ul>
        <p>
          Our approach uncovers that these issues stem largely from the internal token processing and offers a new perspective for enhancing T2I model reliability.
        </p>
      </div>
    </div>
  </section>

  <!-- In-Item Analysis Section -->
  <section class="in-item-analysis" style="margin-bottom: 2rem;">
    <div class="container is-max-desktop">
      <div class="content">
        <h2>Tracing Token Representations in the Text Encoder</h2>
        <p>
          We analyze how information is distributed within each lexical item by generating images from individual token representations. Our experiments show that for most words or expressions, only one or two tokens effectively carry the meaning, while the rest are largely redundant.
        </p>
        <p>
          By masking out these non-representative tokens before image generation, we not only maintain the intended visual output but often see improvements in accuracy—with a notable 21% error reduction. This confirms that a more focused token representation better aligns the generated image with the original prompt.
        </p>
        <figure>
          <img src="static/images/analysis_in_item.png" alt="Visualization of individual token representations within a lexical item.">
          <figcaption>
            Analysis of in-item information flow: Only select tokens capture the full semantic load of the lexical item.
          </figcaption>
        </figure>
        <figure>
          <img src="static/images/repreentative_tokens.jpeg" alt="Highlighted representative tokens among all token representations.">
          <figcaption>
            Typically, one or two tokens are representative while others are redundant.
          </figcaption>
        </figure>
      </div>
    </div>
  </section>

  <!-- Inter-Item Analysis Section -->
  <section class="inter-item-analysis" style="margin-bottom: 2rem;">
    <div class="container is-max-desktop">
      <div class="content">
        <h2>Information Flow Between Lexical Items</h2>
        <p>
          Beyond individual words, our work examines how different lexical items interact during encoding. In 89% of cases, items remain independent; however, in the remaining 11%, unwanted semantic leakage occurs—for example, the word “pool” may inadvertently adopt features of “table,” leading to a pool table effect.
        </p>
        <p>
          We propose a simple yet effective method: by re-encoding the suspected leaked token in isolation and patching it into the prompt’s representation, we reduce semantic leakage errors by 85%. This approach demonstrates that addressing the issue at the token level—in the text encoder—can significantly improve overall generation quality.
        </p>
        <figure>
          <img src="static/images/items_flow.png" alt="Examples of information flow between items.">
          <figcaption>
            Top: Correct information flow between items. Bottom: Unintended leakage where one item influences another.
          </figcaption>
        </figure>
        <figure>
          <img src="static/images/cleaning_method.png" alt="Method for removing semantic leakage by replacing the leaked concept representation.">
          <figcaption>
            Replacing leaked representations with their uncontextualized counterparts effectively restores the intended meaning.
          </figcaption>
        </figure>
      </div>
    </div>
  </section>

  <!-- Catastrophic Negligence Section -->
  <section class="catastrophic-negligence" style="margin-bottom: 2rem;">
    <div class="container is-max-desktop">
      <div class="content">
        <h2>Catastrophic Negligence</h2>
        <p>
          In a small percentage of cases (around 7%), even though the text encoder captures the intended concept, the final image omits it completely—a phenomenon we term catastrophic negligence. Our analysis, supported by tools like Patchscopes, suggests that this may be due to insufficient training examples or difficulties in rendering certain entities. 
        </p>
        <figure>
          <img src="static/images/Catastrophic_negligence.png" alt="Examples of catastrophic negligence where key concepts are omitted.">
          <figcaption>
            Despite accurate encoding, some items are entirely missing from the generated image.
          </figcaption>
        </figure>
      </div>
    </div>
  </section>

  <!-- Supplementary: In-Item Token Distribution Section -->
  <section class="supplementary in-item-tokens" style="margin-bottom: 2rem;">
    <div class="container is-max-desktop">
      <div class="content">
        <h2>Supplementary: In-Item Token Distribution</h2>
        <p>
          Our supplementary analysis further illustrates how semantic weight is unevenly distributed among tokens. In many cases, a single or a couple of sub-tokens carry most of the meaning, while others contribute little. This insight opens up avenues for more efficient token-level interventions in T2I systems.
        </p>
        <figure>
          <img src="static/images/detokenization.gif" alt="Animated view of token-level concept representation.">
          <figcaption class="has-text-centered">
            An animated demonstration of how only a few tokens carry the primary semantic load.
          </figcaption>
        </figure>
      </div>
    </div>
  </section>

  <!-- BibTeX citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
@misc{kaplan2025followflowinformationflow,
      title={Follow the Flow: On Information Flow Across Textual Tokens in Text-to-Image Models}, 
      author={Guy Kaplan and Michael Toker and Yuval Reif and Yonatan Belinkov and Roy Schwartz},
      year={2025},
      eprint={2504.01137},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2504.01137}, 
}
      </code></pre>
    </div>
  </section>

  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
              You are free to borrow the source code of this website, we just ask that you link back to this page in the footer.<br>
              This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>
</html>
